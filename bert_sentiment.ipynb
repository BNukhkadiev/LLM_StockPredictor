{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a8429b5-abda-4859-9d0c-93afa09af9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# import all data\n",
    "df = pd.read_csv('data/upload_DJIA_table.csv', parse_dates=['Date'], index_col='Date')\n",
    "df = df[['Close']]\n",
    "df = df.sort_index()\n",
    "\n",
    "train_data = df[:'2014']\n",
    "test_data = df['2015':]\n",
    "\n",
    "bert_embeddings = np.load('bert_embeddings.npy')\n",
    "fingpt_sentiments = np.load('fingpt_sentiment.npy').astype('float32') \n",
    "\n",
    "bert_embeddings_train = bert_embeddings[:train_data.shape[0]].reshape(-1, 768)\n",
    "bert_embeddings_test = bert_embeddings[train_data.shape[0]:].reshape(-1, 768)\n",
    "\n",
    "\n",
    "def create_sequences(df, seq_length, bert_emb):\n",
    "    xemb, x_pr, x_sent, ys = [], [], [], []\n",
    "    # Iterate over data indices\n",
    "    for i in range(len(df) - seq_length):\n",
    "      \t# Define inputs\n",
    "        xemb.append(bert_emb[i:i+seq_length])\n",
    "        x_pr.append(df.iloc[i:i+seq_length, 0].values.reshape(-1, 1))\n",
    "        x_sent.append(fingpt_sentiments[i:i+seq_length])\n",
    "        \n",
    "        # xemb = np.concatenate((xemb, fingpt_sentiments[i:i+seq_length].reshape(-1, 1)), axis=1)\n",
    "        # Define target\n",
    "        y = df.iloc[i+seq_length, 0]\n",
    "        # xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xemb), np.array(x_pr).squeeze(), np.array(x_sent), np.array(ys)\n",
    "    \n",
    "\n",
    "X_train_emb, X_train_pr, X_train_sent, y_train = create_sequences(train_data, 60, bert_embeddings_train)\n",
    "X_test_emb, X_test_pr, X_test_sent, y_test = create_sequences(test_data, 60, bert_embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0a527a2-935a-4809-a162-83d5c395059b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1551, 60), (318, 60))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sent.shape, X_test_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fda13211-51f3-4192-aefc-846657dbace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes:  (1551, 60, 768) (1551, 60) (1551, 60) (1551,)\n",
      "Test shapes:  (318, 60, 768) (318, 60) (318, 60) (318,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shapes: \", X_train_emb.shape, X_train_pr.shape, X_train_sent.shape, y_train.shape)\n",
    "print(\"Test shapes: \", X_test_emb.shape, X_test_pr.shape, X_test_sent.shape, y_test.shape)\n",
    "\n",
    "# convert to torch dataset\n",
    "dataset_train = TensorDataset(\n",
    "    torch.from_numpy(X_train_emb).float(),\n",
    "    torch.from_numpy(X_train_pr).float(),\n",
    "    torch.from_numpy(X_train_sent).float(),\n",
    "    torch.from_numpy(y_train).float()\n",
    ")\n",
    "dataset_test = TensorDataset(\n",
    "    torch.from_numpy(X_test_emb).float(),\n",
    "    torch.from_numpy(X_test_pr).float(),\n",
    "    torch.from_numpy(X_test_sent).float(),\n",
    "    torch.from_numpy(y_test).float()\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2cc49abb-d4bd-422e-98a4-b10c91bfa35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, embedding_dim, price_dim, sent_dim, hidden_dim, num_layers):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        self.lstm_bert = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.lstm_price = nn.LSTM(price_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.lstm_sent = nn.LSTM(sent_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        # self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, bert_x, price_x, sent_x):\n",
    "        lstm_out_bert, _ = self.lstm_bert(bert_x)\n",
    "        lstm_out_price, _ = self.lstm_price(price_x)\n",
    "        lstm_out_sent, _ = self.lstm_sent(sent_x)\n",
    "        # Only consider the output of the last LSTM cell\n",
    "        last_out_bert = lstm_out_bert[:, -1, :]\n",
    "        last_out_price = lstm_out_price[:, -1, :]\n",
    "        last_out_sent = lstm_out_sent[:, -1, :]\n",
    "        \n",
    "        # Concatenate the outputs of both LSTMs\n",
    "        combined_out = torch.cat((last_out_bert, last_out_price, last_out_sent), dim=1)\n",
    "        output = self.head(combined_out)\n",
    "        return output\n",
    "\n",
    "# Model parameters\n",
    "embedding_dim = 768  # Size of BERT embeddings\n",
    "price_dim = 1        # Each stock price is a single number\n",
    "sent_dim = 1        # Each sentiment is a single number\n",
    "\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "\n",
    "model = StockPredictor(embedding_dim, price_dim, sent_dim, hidden_dim, num_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be347a74-7360-4836-9204-74f19db79dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 144917312.0, MAE: 12038.16065684455\n",
      "Epoch 2, Loss: 162123424.0, MAE: 12732.76969084103\n",
      "Epoch 3, Loss: 116569328.0, MAE: 10796.727652395424\n",
      "Epoch 4, Loss: 33920120.0, MAE: 5824.0982134576\n",
      "Epoch 5, Loss: 13177386.0, MAE: 3630.0669415315197\n",
      "Epoch 6, Loss: 7766516.5, MAE: 2786.8470535714728\n",
      "Epoch 7, Loss: 8222755.5, MAE: 2867.534742596853\n",
      "Epoch 8, Loss: 7412333.5, MAE: 2722.5601003467305\n",
      "Epoch 9, Loss: 4933209.0, MAE: 2221.082844020006\n",
      "Epoch 10, Loss: 4819522.0, MAE: 2195.3409757939653\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_bert, batch_price, batch_sent, batch_y in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_bert, batch_price.unsqueeze(-1), batch_sent.unsqueeze(-1))\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}, MAE: {loss.item()**0.5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60fddd7f-00e0-44b5-89c3-831ac5e29aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  tensor(23709278.)\n",
      "Test MAE:  tensor(4869.2173)\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "\n",
    "mse = torchmetrics.MeanSquaredError()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_bert, batch_price, batch_sent, batch_y in dataloader_test:\n",
    "        outputs = model(batch_bert, batch_price.unsqueeze(-1), batch_sent.unsqueeze(-1))\n",
    "        mse(outputs.squeeze(), batch_y)\n",
    "\n",
    "print(\"Test MSE: \", mse.compute())\n",
    "print(\"Test MAE: \", mse.compute()**0.5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4196348-5179-4f6a-8ea1-447cee513531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
