{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da379302-b109-494a-a5b5-b97b52ae6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23567fa5-f680-4180-973a-416f7fa9e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = pd.DataFrame()\n",
    "\n",
    "combined_news_djia = pd.read_csv('../data/Combined_News_DJIA.csv')\n",
    "combined_news_djia['Top1'] = combined_news_djia['Top1'].apply(lambda x: x[2:-1] if x[0]=='b' else x)\n",
    "combined_news_djia['Top2'] = combined_news_djia['Top2'].apply(lambda x: x[2:-1] if x[0]=='b' else x)\n",
    "\n",
    "t_data['Text'] = combined_news_djia['Top1'] + \" \" + combined_news_djia['Top2']\n",
    "t_data['Date'] = combined_news_djia['Date']\n",
    "t_data.set_index('Date')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "tokenizer = WordPunctTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process_headline(x):\n",
    "    return \" \".join([w.lower() for w in tokenizer.tokenize(x) if not w.lower() in stop_words])\n",
    "\n",
    "t_data['Text'] = t_data['Text'].apply(process_headline)\n",
    "t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35019d74-fd71-44b2-aa59-311f4cc1b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "\n",
    "# Download FastText word vectors\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # Download English language embeddings\n",
    "ft = fasttext.load_model('../../NLPstockPredictions/cc.en.300.bin')  # Load the downloaded model\n",
    "\n",
    "def get_embeddings(data):\n",
    "    combo = []\n",
    "    for row in data.values:\n",
    "        news_embedding = np.mean([ft.get_word_vector(word) for word in row[0].split()], axis=0)\n",
    "        combo.append(news_embedding)\n",
    "    return np.array(combo), data.values[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a214078-569d-4ef4-9fd2-ad8a7b114557",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = get_embeddings(t_data)\n",
    "with open('../fasttext_embeddings.npy', 'wb') as f:\n",
    "    np.save(f, t_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
